name: finetune_colanet_grid
version: v1
group0:
    rbwd:
    - True
    - True
    - False    
    - True
    wt:
    - 0
    - 3
    - 3
    - 3
    flow:
    - False
    - False
    - True
    - True
    flow_method:
    - "skip"
    - "skip"
    - "svnlb"
    - "svnlb"
cfg:
    arch_name: "colanet"
    root: "/home/gauenk/Documents/packages/aaai23"
    sigma: 30
    pretrained_path: "pretrained_s30.pt"
    pretrained_root: "/home/gauenk/Documents/packages/colanet"
    pretrained_type: "git"
    pretrained_load: True
    python_lib: "colanet"
    device: "cuda:0"
    dname: "davis"
    sim_type: "g"
    sim_device: "cuda:0"
    # ndevices: 2
    ndevices: 1
    swa: False
    seed: 123
    k_s: 100
    k_a: 100
    isize: "128_128"
    nframes: 5
    ws: 20
    cropmode: 'sobel'
    saved_dir: "/home/gauenk/Documents/packages/aaai23/output/run_models/colanet/"
    checkpoint_dir: "/home/gauenk/Documents/packages/aaai23/output/train/colanet/checkpoints/"
    spatial_chunk_size: 0
    spatial_chunk_overlap: 0.
    temporal_chunk_size: 5
    temporal_chunk_overlap: 0.
    longest_space_chunk: False
    # accumulate_grad_batches: 1
    accumulate_grad_batches: 2
    batch_size: 1
    batch_size_tr: 4
    batch_size_val: 1
    batch_size_te: 1
    lr_init: 5.0e-5
    lr_final: 1.0e-8
    deno_clamp: True
    scheduler: "steplr"
    swa_epoch_start: 0.8
    weight_decay: 0
    warmup_epochs: 0
    task: "rgb_denoise"
    noise_version: "rgb_noise"
    gradient_clip_val: 0.5
    optim: "adam"
    momentum: 0.
    aug_training_scales:
    - 1.
    aug_training_flips: False
    nsamples_tr: 400
    nsamples_val: 30
    nsamples_at_testing: 2
    limit_train_batches: 1.
    rand_order_tr : True
    index_skip_tr: 1
    nepochs: 30
    bw: True
