name: finetune_colanet
version: v1
group0:
    sigma:
    - 50
    - 30
    - 15
    pretrained_path:
    - "pretrained_s50.pt"
    - "pretrained_s30.pt"
    - "pretrained_s15.pt"
    k_s:
    - 100
    - 100
    - 100
    k_a:
    - 100
    - 100
    - 100
cfg:
    arch_name: "colanet"
    root: "/home/gauenk/Documents/packages/aaai23"
    pretrained_root: "/home/gauenk/Documents/packages/colanet"
    python_lib: "colanet"
    device: "cuda:0"
    dname: "davis_cropped"
    sim_type: "g"
    sim_device: "cuda:0"
    ndevices: 1
    swa: False
    seed: 123
    isize: "128_128"
    nframes: 5
    pretrained_load: True
    pretrained_type: "git"
    ws: 21
    wt: 3
    rbwd: True
    flow: False
    saved_dir: "/home/gauenk/Documents/packages/aaai23/output/run_models/colanet/"
    checkpoint_dir: "/home/gauenk/Documents/packages/aaai23/output/train/colanet/checkpoints/"
    spatial_chunk_size: 0
    spatial_chunk_overlap: 0.
    temporal_chunk_size: 5
    temporal_chunk_overlap: 0.
    longest_space_chunk: False
    accumulate_grad_batches: 2
    batch_size: 4
    batch_size_tr: 4
    batch_size_val: 2
    lr_init: 1.0e-5
    lr_final: 1.0e-8
    scheduler: "default"
    weight_decay: 0.
    warmup_epochs: 0
    task: "rgb_denoise"
    noise_version: "rgb_noise"
    gradient_clip_val: 0.5
    aug_training_scales:
    - 0.5
    - 0.75
    - 1.
    aug_training_flips: True
    scheduler: "default"
    nsamples_at_testing: 2
    nsamples_tr: 0
    nsamples_val: 2
    limit_train_batches: 0.25
    nepochs: 15
    bw: True
global_grids: {}
